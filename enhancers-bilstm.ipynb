{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/overcoder/Library/Python/3.13/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/overcoder/Library/Python/3.13/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/overcoder/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-31T09:58:55.648821Z",
     "iopub.status.busy": "2025-10-31T09:58:55.648533Z",
     "iopub.status.idle": "2025-10-31T09:58:55.656293Z",
     "shell.execute_reply": "2025-10-31T09:58:55.655382Z",
     "shell.execute_reply.started": "2025-10-31T09:58:55.648802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 1 — Setup (MPS device, imports, seeds)\n",
    "# ================================================================\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:13.349271Z",
     "iopub.status.busy": "2025-10-31T10:02:13.348503Z",
     "iopub.status.idle": "2025-10-31T10:02:13.357683Z",
     "shell.execute_reply": "2025-10-31T10:02:13.357021Z",
     "shell.execute_reply.started": "2025-10-31T10:02:13.349247Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fasta file: Vista_Dataset/vista_sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — file locate (tries common Kaggle and /mnt/data)\n",
    "candidate_paths = [\n",
    "    \"/kaggle/input/vista-sequence/vista_sequences.fasta\",\n",
    "    \"Vista_Dataset/vista_sequences.fasta\",\n",
    "    \"/mnt/data/vista_sequence.fasta\",\n",
    "    \"/kaggle/working/vista_sequence.fasta\",\n",
    "    \"/kaggle/input/vista-enhancers/vista_sequence.fasta\",\n",
    "]\n",
    "fasta_path = None\n",
    "for p in candidate_paths:\n",
    "    if os.path.exists(p):\n",
    "        fasta_path = p\n",
    "        break\n",
    "if fasta_path is None:\n",
    "    raise FileNotFoundError(f\"vista_sequence.fasta not found. Tried paths:\\n\" + \"\\n\".join(candidate_paths))\n",
    "print(\"Using fasta file:\", fasta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:16.034003Z",
     "iopub.status.busy": "2025-10-31T10:02:16.033696Z",
     "iopub.status.idle": "2025-10-31T10:02:16.233289Z",
     "shell.execute_reply": "2025-10-31T10:02:16.232466Z",
     "shell.execute_reply.started": "2025-10-31T10:02:16.033963Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed sequences: 3408\n",
      "H: Human|chr16:86430087-86430726 | element 1 | positive  | neural tube[12/12] | hindbrain (rhombencephalon)[12/12] | limb[3/12] | cranial nerve[8/12]\n",
      "H: Human|chr16:85620095-85621736 | element 2 | negative\n",
      "H: Human|chr16:80423343-80424652 | element 3 | negative\n",
      "H: Human|chr16:80372593-80373755 | element 4 | positive  | neural tube[6/10] | hindbrain (rhombencephalon)[10/10] | midbrain (mesencephalon)[10/10]\n",
      "H: Human|chr16:79969907-79971297 | element 5 | negative\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — parse FASTA and build dataframe\n",
    "def parse_fasta_to_records(path):\n",
    "    # Expect fasta headers to include label/species; if not, you may need to adapt to your fasta header format.\n",
    "    records = []\n",
    "    with open(path, 'r') as fh:\n",
    "        header = None\n",
    "        seq_lines = []\n",
    "        for line in fh:\n",
    "            line=line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                if header is not None:\n",
    "                    seq = \"\".join(seq_lines).upper()\n",
    "                    records.append((header, seq))\n",
    "                header = line[1:]\n",
    "                seq_lines = []\n",
    "            else:\n",
    "                seq_lines.append(line)\n",
    "        # last\n",
    "        if header is not None:\n",
    "            seq = \"\".join(seq_lines).upper()\n",
    "            records.append((header, seq))\n",
    "    return records\n",
    "\n",
    "records = parse_fasta_to_records(fasta_path)\n",
    "print(\"Parsed sequences:\", len(records))\n",
    "# Inspect a few headers to ensure label extraction\n",
    "for h,s in records[:5]:\n",
    "    print(\"H:\", h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:20.304265Z",
     "iopub.status.busy": "2025-10-31T10:02:20.303494Z",
     "iopub.status.idle": "2025-10-31T10:02:20.378785Z",
     "shell.execute_reply": "2025-10-31T10:02:20.378027Z",
     "shell.execute_reply.started": "2025-10-31T10:02:20.304236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3408, 4)\n",
      "species\n",
      "human    2002\n",
      "mouse    1406\n",
      "Name: count, dtype: int64\n",
      "Enhancer flag counts: enhancer\n",
      "1    1750\n",
      "0    1658\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>sequence</th>\n",
       "      <th>species</th>\n",
       "      <th>enhancer</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human|chr16:86430087-86430726 | element 1 | po...</td>\n",
       "      <td>AACTGAAGGGACCCCGTTAGCATATAAACAAAAGGTGGGGGGTAGC...</td>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human|chr16:85620095-85621736 | element 2 | ne...</td>\n",
       "      <td>GGCCCTGGTATGTTTGTTCTTCCAGGGGCTCCCAGGATGGATCCAG...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human|chr16:80423343-80424652 | element 3 | ne...</td>\n",
       "      <td>AAGATTGCCATTTGGGGTGTTTCTTGGGGCTAAGAACCATGAAGAC...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human|chr16:80372593-80373755 | element 4 | po...</td>\n",
       "      <td>GTGACAGAGACAGACAGTGACAGAGACAGATTTTAGAATTTGAACA...</td>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human|chr16:79969907-79971297 | element 5 | ne...</td>\n",
       "      <td>TGACACCCACTATTATCCAGTCCTTGATAAACCTCTTTATTTGTTC...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Human|chr16:79949950-79951518 | element 6 | ne...</td>\n",
       "      <td>AGTCACCCAGGTGGTAGTGGGCTGCAGATGCTGTGGGTTTTGTTTC...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Human|chr16:79026563-79028162 | element 7 | ne...</td>\n",
       "      <td>ACAGAAGCCTCAAGCCTAACCAACAAGAAAGATCACTTCATATGCA...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Human|chr16:78933253-78934686 | element 9 | ne...</td>\n",
       "      <td>TTGTTCCGGAAACCTAACTCCAAATCTTTGAACTTCCTAGAAACCT...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Human|chr16:86430087-86430726 | element 1 | po...   \n",
       "1  Human|chr16:85620095-85621736 | element 2 | ne...   \n",
       "2  Human|chr16:80423343-80424652 | element 3 | ne...   \n",
       "3  Human|chr16:80372593-80373755 | element 4 | po...   \n",
       "4  Human|chr16:79969907-79971297 | element 5 | ne...   \n",
       "5  Human|chr16:79949950-79951518 | element 6 | ne...   \n",
       "6  Human|chr16:79026563-79028162 | element 7 | ne...   \n",
       "7  Human|chr16:78933253-78934686 | element 9 | ne...   \n",
       "\n",
       "                                            sequence species  enhancer  \\\n",
       "0  AACTGAAGGGACCCCGTTAGCATATAAACAAAAGGTGGGGGGTAGC...   human         1   \n",
       "1  GGCCCTGGTATGTTTGTTCTTCCAGGGGCTCCCAGGATGGATCCAG...   human         0   \n",
       "2  AAGATTGCCATTTGGGGTGTTTCTTGGGGCTAAGAACCATGAAGAC...   human         0   \n",
       "3  GTGACAGAGACAGACAGTGACAGAGACAGATTTTAGAATTTGAACA...   human         1   \n",
       "4  TGACACCCACTATTATCCAGTCCTTGATAAACCTCTTTATTTGTTC...   human         0   \n",
       "5  AGTCACCCAGGTGGTAGTGGGCTGCAGATGCTGTGGGTTTTGTTTC...   human         0   \n",
       "6  ACAGAAGCCTCAAGCCTAACCAACAAGAAAGATCACTTCATATGCA...   human         0   \n",
       "7  TTGTTCCGGAAACCTAACTCCAAATCTTTGAACTTCCTAGAAACCT...   human         0   \n",
       "\n",
       "   seq_len  \n",
       "0      640  \n",
       "1     1642  \n",
       "2     1310  \n",
       "3     1163  \n",
       "4     1391  \n",
       "5     1569  \n",
       "6     1600  \n",
       "7     1434  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 — build dataframe with label extraction (try to infer from header)\n",
    "rows = []\n",
    "for header, seq in records:\n",
    "    h = header.lower()\n",
    "    # Best-effort inference:\n",
    "    if \"human\" in h or \"hs\" in h:\n",
    "        species = \"human\"\n",
    "    elif \"mouse\" in h or \"mm\" in h:\n",
    "        species = \"mouse\"\n",
    "    else:\n",
    "        # fallback: if file has species in separate field, split by '|' or whitespace:\n",
    "        species = \"unknown\"\n",
    "    # enhancer presence detection:\n",
    "    if \"enhancer\" in h or \"positive\" in h or \"pos\" in h:\n",
    "        enhancer_flag = 1\n",
    "    elif \"non\" in h or \"negative\" in h or \"neg\" in h or \"not\" in h:\n",
    "        enhancer_flag = 0\n",
    "    else:\n",
    "        # fallback: try numeric statuses\n",
    "        enhancer_flag = None\n",
    "    rows.append({\"header\": header, \"sequence\": seq, \"species\": species, \"enhancer\": enhancer_flag})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.shape)\n",
    "df['seq_len'] = df['sequence'].str.len()\n",
    "df.seq_len.describe()\n",
    "# If many 'unknown' or enhancer None, print sample to let user confirm header format:\n",
    "print(df['species'].value_counts(dropna=False))\n",
    "print(\"Enhancer flag counts:\", df['enhancer'].value_counts(dropna=False))\n",
    "df.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:23.800233Z",
     "iopub.status.busy": "2025-10-31T10:02:23.799561Z",
     "iopub.status.idle": "2025-10-31T10:02:23.856848Z",
     "shell.execute_reply": "2025-10-31T10:02:23.856171Z",
     "shell.execute_reply.started": "2025-10-31T10:02:23.800208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancer sequences (for scenario1): 1750\n",
      "class_s2\n",
      "2    1658\n",
      "0    1029\n",
      "1     721\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — filter & prepare labels for scenarios\n",
    "# Scenario 1: only enhancer sequences (paper's first scenario predicted human vs mouse among enhancers).\n",
    "df_enhancers = df[df['enhancer']==1].copy()\n",
    "print(\"Enhancer sequences (for scenario1):\", len(df_enhancers))\n",
    "\n",
    "# Scenario 2: all sequences -> classes: human_enhancer, mouse_enhancer, no_enhancer\n",
    "def class_label_row(r):\n",
    "    if r.enhancer==1 and r.species==\"human\":\n",
    "        return 0  # human enhancer\n",
    "    if r.enhancer==1 and r.species==\"mouse\":\n",
    "        return 1  # mouse enhancer\n",
    "    return 2      # no enhancer\n",
    "\n",
    "df['class_s2'] = df.apply(class_label_row, axis=1)\n",
    "print(df['class_s2'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:28.338628Z",
     "iopub.status.busy": "2025-10-31T10:02:28.338351Z",
     "iopub.status.idle": "2025-10-31T10:02:28.345738Z",
     "shell.execute_reply": "2025-10-31T10:02:28.345018Z",
     "shell.execute_reply.started": "2025-10-31T10:02:28.338609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 6 — encoding schemes\n",
    "INT_MAP = {'A':1,'C':3,'G':2,'T':4,'N':0}\n",
    "ATOMIC_MAP = {'A':70,'C':58,'G':78,'T':66,'N':0}\n",
    "EIIP_MAP = {'A':0.1260,'C':0.1340,'G':0.0806,'T':0.1335,'N':0.0}\n",
    "\n",
    "# BFDNA: per-sequence frequencies (the paper uses for each base the frequency across the whole sequence;\n",
    "# then every position mapped to that base's frequency value).\n",
    "def encode_sequence_integer(seq):\n",
    "    return [INT_MAP.get(b,0) for b in seq]\n",
    "\n",
    "def encode_sequence_atomic(seq):\n",
    "    return [ATOMIC_MAP.get(b,0) for b in seq]\n",
    "\n",
    "def encode_sequence_eiip(seq):\n",
    "    return [EIIP_MAP.get(b,0.0) for b in seq]\n",
    "\n",
    "def encode_sequence_bfdna(seq):\n",
    "    L = len(seq)\n",
    "    # count bases\n",
    "    counts = {'A':0,'C':0,'G':0,'T':0}\n",
    "    for b in seq:\n",
    "        if b in counts:\n",
    "            counts[b]+=1\n",
    "    freqs = {b: (counts[b]/L if L>0 else 0.0) for b in counts}\n",
    "    # map each position to its base frequency value (paper example uses this)\n",
    "    return [freqs.get(b,0.0) for b in seq]\n",
    "\n",
    "ENCODERS = {\n",
    "    'integer': encode_sequence_integer,\n",
    "    'atomic': encode_sequence_atomic,\n",
    "    'eiip': encode_sequence_eiip,\n",
    "    'bfdna': encode_sequence_bfdna\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:27.563993Z",
     "iopub.status.busy": "2025-10-31T10:05:27.563365Z",
     "iopub.status.idle": "2025-10-31T10:05:29.360531Z",
     "shell.execute_reply": "2025-10-31T10:05:29.359656Z",
     "shell.execute_reply.started": "2025-10-31T10:05:27.563955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFDNA shape (3408, 2000) maxlen 2000\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — prepare encoded arrays, pad sequences to max_len and min-max normalize per scheme\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def prepare_encoded_array(seqs, encoder_name, max_len_cap=2000):\n",
    "    \"\"\"Encode and pad sequences; truncate to max_len_cap to avoid OOM.\"\"\"\n",
    "    enc = ENCODERS[encoder_name]\n",
    "    encoded = [enc(s) for s in seqs]\n",
    "    # Cap very long sequences\n",
    "    if max_len_cap:\n",
    "        encoded = [x[:max_len_cap] for x in encoded]\n",
    "    max_len = max(len(x) for x in encoded)\n",
    "    padded = pad_sequences(encoded, maxlen=max_len, dtype='float32',\n",
    "                           padding='post', truncating='post', value=0.0)\n",
    "    # Min–max normalize across dataset\n",
    "    minv, maxv = padded.min(), padded.max()\n",
    "    if maxv > minv:\n",
    "        padded = (padded - minv) / (maxv - minv)\n",
    "    return padded, max_len\n",
    "\n",
    "# Example for BFDNA\n",
    "X_bfdna, maxlen_bfdna = prepare_encoded_array(df['sequence'].tolist(), 'bfdna')\n",
    "print(\"BFDNA shape\", X_bfdna.shape, \"maxlen\", maxlen_bfdna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:32.349161Z",
     "iopub.status.busy": "2025-10-31T10:05:32.348435Z",
     "iopub.status.idle": "2025-10-31T10:05:32.356337Z",
     "shell.execute_reply": "2025-10-31T10:05:32.355675Z",
     "shell.execute_reply.started": "2025-10-31T10:05:32.349130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 8 — helper: metric computations used in paper (CSI, G-mean)\n",
    "def classification_metrics(y_true, y_pred, average='binary'):\n",
    "    # y_true: 1d labels\n",
    "    # y_pred: 1d predicted labels\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    # compute confusion matrix elements (for binary)\n",
    "    if average=='binary' or len(np.unique(y_true))==2:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        # CSI = Precision + TPR - 1 (paper definition)\n",
    "        tpr = tp/(tp+fn) if (tp+fn)>0 else 0.0\n",
    "        csi = prec + tpr - 1\n",
    "        specificity = tn/(tn+fp) if (tn+fp)>0 else 0.0\n",
    "        gmean = math.sqrt(rec * specificity)\n",
    "    else:\n",
    "        # for multiclass, compute macro variants:\n",
    "        csi = None\n",
    "        gmean = None\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    return {'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'CSI':csi, 'G-mean':gmean, 'MCC':mcc, 'Kappa':kappa}\n",
    "\n",
    "# multiclass macro-average ROC AUC:\n",
    "def multiclass_roc_auc_score(y_true, y_proba, average=\"macro\"):\n",
    "    # y_true integer labels, y_proba: N x C\n",
    "    try:\n",
    "        return roc_auc_score(to_categorical(y_true), y_proba, average=average, multi_class='ovr')\n",
    "    except Exception as e:\n",
    "        print(\"roc_auc_score error:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:38.278702Z",
     "iopub.status.busy": "2025-10-31T10:05:38.278413Z",
     "iopub.status.idle": "2025-10-31T10:05:38.288239Z",
     "shell.execute_reply": "2025-10-31T10:05:38.287518Z",
     "shell.execute_reply.started": "2025-10-31T10:05:38.278681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 9 — model builders (scenario1: binary, scenario2: multiclass)\n",
    "def build_bilstm_scenario1(input_shape):\n",
    "    # paper: 256 BiLSTM -> dropout .15 -> 128 BiLSTM -> dropout .2 -> 64 BiLSTM -> dropout .2\n",
    "    # SeLU activations; BatchNorm; Flatten; Dense 512,256,128; Sigmoid output\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, activation='tanh'))(inp)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.15, seed=SEED)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, activation='tanh'))(x)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.20, seed=SEED)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, activation='tanh'))(x)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.20, seed=SEED)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='selu')(x)\n",
    "    x = layers.Dense(256, activation='selu')(x)\n",
    "    x = layers.Dense(128, activation='selu')(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_bilstm_scenario2(input_shape, n_classes):\n",
    "    # paper: 128 BiLSTM -> dropout .15 -> 64 BiLSTM -> dropout .2 -> BatchNorm -> Flatten -> Dense 256,128 -> Softmax\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, activation='tanh'))(inp)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.15, seed=SEED)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, activation='tanh'))(x)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.20, seed=SEED)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='selu')(x)\n",
    "    x = layers.Dense(128, activation='selu')(x)\n",
    "    out = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:41.572877Z",
     "iopub.status.busy": "2025-10-31T10:05:41.572596Z",
     "iopub.status.idle": "2025-10-31T10:05:41.584563Z",
     "shell.execute_reply": "2025-10-31T10:05:41.584036Z",
     "shell.execute_reply.started": "2025-10-31T10:05:41.572858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 10 — training helper to train and evaluate a model; returns history and metrics\n",
    "def train_and_evaluate_model(X, y, scenario=1, encoder_name='bfdna', batch_size=32, epochs=500):\n",
    "    # X: padded 2D array (samples, seq_len). We'll reshape to (samples, seq_len, 1)\n",
    "    X3 = np.expand_dims(X, -1)\n",
    "    if scenario == 1:\n",
    "        # binary: y are species labels for enhancer-only samples (human=0, mouse=1)\n",
    "        y_bin = y  # should be 0/1\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X3, y_bin, test_size=0.30, random_state=SEED, stratify=y_bin)\n",
    "        # split temp into val/test equally: 0.15 each of full\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp)\n",
    "        model = build_bilstm_scenario1(input_shape=X3.shape[1:])\n",
    "        opt = optimizers.RMSprop()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    else:\n",
    "        # multi-class: y are 0..C-1\n",
    "        n_classes = len(np.unique(y))\n",
    "        y_cat = to_categorical(y, num_classes=n_classes)\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X3, y_cat, test_size=0.30, random_state=SEED, stratify=y)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=np.argmax(y_temp, axis=1))\n",
    "        model = build_bilstm_scenario2(input_shape=X3.shape[1:], n_classes=n_classes)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    outdir = f\"./outputs/{encoder_name}/scenario{scenario}\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    ckpt = callbacks.ModelCheckpoint(os.path.join(outdir, \"best_model.h5\"), monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    csvlog = callbacks.CSVLogger(os.path.join(outdir, \"training_log.csv\"))\n",
    "    # Paper trained full 500 epochs — we avoid EarlyStopping to be faithful, but you can enable it.\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[ckpt, csvlog], verbose=2)\n",
    "    # load best\n",
    "    model.load_weights(os.path.join(outdir, \"best_model.h5\"))\n",
    "    # Predict\n",
    "    if scenario==1:\n",
    "        y_pred_prob = model.predict(X_test).ravel()\n",
    "        y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "        y_true = y_test\n",
    "    else:\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # metrics\n",
    "    results = {}\n",
    "    if scenario==1:\n",
    "        auc_score = roc_auc_score(y_true, y_pred_prob)\n",
    "        m = classification_metrics(y_true, y_pred, average='binary')\n",
    "        m['AUC'] = auc_score\n",
    "        results = m\n",
    "    else:\n",
    "        auc_score = multiclass_roc_auc_score(y_true, y_pred_prob)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        # For CSI and G-mean paper printed single scores; we will leave CSI/G-mean as None for multiclass (could compute per-class)\n",
    "        results = {'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'CSI':None, 'G-mean':None, 'MCC':mcc, 'Kappa':kappa, 'AUC':auc_score}\n",
    "\n",
    "    # save predictions & test y\n",
    "    np.savez(os.path.join(outdir, \"test_preds_and_truth.npz\"), y_true=y_true, y_pred=y_pred, y_pred_prob=y_pred_prob)\n",
    "    # save training history\n",
    "    pd.DataFrame(history.history).to_csv(os.path.join(outdir, \"history.csv\"), index=False)\n",
    "    return model, history, results, (X_test, y_test, y_pred, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:44.999279Z",
     "iopub.status.busy": "2025-10-31T10:05:44.998599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Encoder: integer\n",
      "Training Scenario 1 (human vs mouse enhancers) for encoder integer\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_loss improved from None to 2.63610, saving model to ./outputs/integer/scenario1/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 - 288s - 4s/step - accuracy: 0.5184 - loss: 3.4620 - val_accuracy: 0.4122 - val_loss: 2.6361\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_loss did not improve from 2.63610\n",
      "77/77 - 317s - 4s/step - accuracy: 0.5429 - loss: 1.1237 - val_accuracy: 0.5878 - val_loss: 3.2987\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_loss improved from 2.63610 to 2.53238, saving model to ./outputs/integer/scenario1/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 - 360s - 5s/step - accuracy: 0.4971 - loss: 1.0098 - val_accuracy: 0.4122 - val_loss: 2.5324\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_loss did not improve from 2.53238\n",
      "77/77 - 367s - 5s/step - accuracy: 0.5510 - loss: 0.8751 - val_accuracy: 0.5878 - val_loss: 25.9148\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_loss did not improve from 2.53238\n",
      "77/77 - 416s - 5s/step - accuracy: 0.5469 - loss: 0.8229 - val_accuracy: 0.5878 - val_loss: 19.5115\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_loss did not improve from 2.53238\n",
      "77/77 - 487s - 6s/step - accuracy: 0.5649 - loss: 0.7651 - val_accuracy: 0.5878 - val_loss: 6.7496\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_loss did not improve from 2.53238\n",
      "77/77 - 579s - 8s/step - accuracy: 0.5845 - loss: 0.7127 - val_accuracy: 0.5878 - val_loss: 62.1056\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: val_loss did not improve from 2.53238\n",
      "77/77 - 383s - 5s/step - accuracy: 0.5673 - loss: 0.7756 - val_accuracy: 0.4122 - val_loss: 278.9758\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: val_loss did not improve from 2.53238\n",
      "77/77 - 365s - 5s/step - accuracy: 0.5910 - loss: 0.6891 - val_accuracy: 0.4122 - val_loss: 292.1120\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Train scenario1\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining Scenario 1 (human vs mouse enhancers) for encoder\u001b[39m\u001b[33m\"\u001b[39m, encoder)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m model1, hist1, res1, testinfo1 = \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m all_results[\u001b[33m'\u001b[39m\u001b[33mscenario1\u001b[39m\u001b[33m'\u001b[39m][encoder] = res1\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mScenario1 results:\u001b[39m\u001b[33m\"\u001b[39m, res1)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_and_evaluate_model\u001b[39m\u001b[34m(X, y, scenario, encoder_name, batch_size, epochs)\u001b[39m\n\u001b[32m     27\u001b[39m csvlog = callbacks.CSVLogger(os.path.join(outdir, \u001b[33m\"\u001b[39m\u001b[33mtraining_log.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Paper trained full 500 epochs — we avoid EarlyStopping to be faithful, but you can enable it.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsvlog\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# load best\u001b[39;00m\n\u001b[32m     31\u001b[39m model.load_weights(os.path.join(outdir, \u001b[33m\"\u001b[39m\u001b[33mbest_model.h5\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 11 — full pipeline loop over encoders and both scenarios (warning: heavy; you can run one encoder at a time)\n",
    "encoders = ['integer','atomic','eiip','bfdna']\n",
    "all_results = {'scenario1':{}, 'scenario2':{}}\n",
    "for encoder in encoders:\n",
    "    print(\"\\n\\n### Encoder:\", encoder)\n",
    "    X, _ = prepare_encoded_array(df['sequence'].tolist(), encoder)\n",
    "    # Scenario 1 uses only enhancer sequences and species labels among enhancers\n",
    "    df_e = df[df['enhancer']==1].reset_index(drop=True)\n",
    "    X_e, _ = prepare_encoded_array(df_e['sequence'].tolist(), encoder)\n",
    "    # species mapping among enhancers:\n",
    "    species_map = df_e['species'].map({'human':0,'mouse':1}).fillna(0).astype(int).values\n",
    "    # Train scenario1\n",
    "    print(\"Training Scenario 1 (human vs mouse enhancers) for encoder\", encoder)\n",
    "    model1, hist1, res1, testinfo1 = train_and_evaluate_model(X_e, species_map, scenario=1, encoder_name=encoder, batch_size=16, epochs=10)\n",
    "    all_results['scenario1'][encoder] = res1\n",
    "    print(\"Scenario1 results:\", res1)\n",
    "    # Scenario2: multiclass\n",
    "    print(\"Training Scenario 2 (human enhancer / mouse enhancer / no enhancer) for encoder\", encoder)\n",
    "    # class_s2 in df already (0 human enh,1 mouse enh,2 no enhancer)\n",
    "    X_all, _ = prepare_encoded_array(df['sequence'].tolist(), encoder)\n",
    "    classes_s2 = df['class_s2'].values\n",
    "    model2, hist2, res2, testinfo2 = train_and_evaluate_model(X_all, classes_s2, scenario=2, encoder_name=encoder, batch_size=32, epochs=10)\n",
    "    all_results['scenario2'][encoder] = res2\n",
    "    print(\"Scenario2 results:\", res2)\n",
    "    # Save intermediate results\n",
    "    pd.DataFrame(all_results).to_csv(f\"./outputs/{encoder}_summary_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 12 — plotting helpers (example: training curves, ROC, confusion matrix)\n",
    "import itertools\n",
    "def plot_training(history_csv_path=None, history_obj=None, outpath=None):\n",
    "    if history_obj is not None:\n",
    "        history = history_obj.history\n",
    "    else:\n",
    "        history = pd.read_csv(history_csv_path).to_dict()\n",
    "    plt.figure(figsize=(10,4))\n",
    "    if 'loss' in history:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(history['loss'], label='train_loss')\n",
    "        plt.plot(history['val_loss'], label='val_loss')\n",
    "        plt.legend(); plt.title(\"Loss\")\n",
    "    if 'accuracy' in history:\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(history['accuracy'], label='train_acc')\n",
    "        plt.plot(history['val_accuracy'], label='val_acc')\n",
    "        plt.legend(); plt.title(\"Accuracy\")\n",
    "    if outpath:\n",
    "        plt.savefig(outpath)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues, outpath=None):\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label'); plt.title(title)\n",
    "    if outpath:\n",
    "        plt.savefig(outpath)\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_binary(y_true, y_prob, outpath=None):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC'); plt.legend()\n",
    "    if outpath:\n",
    "        plt.savefig(outpath)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8617971,
     "sourceId": 13566704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
