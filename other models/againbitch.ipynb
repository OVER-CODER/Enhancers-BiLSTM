{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7cG2xkihfCNt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, LabelEncoder\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GuXGAwxkfNo6"
      },
      "outputs": [],
      "source": [
        "FASTA_PATH = \"Vista_Dataset/vista_sequences.fasta\"\n",
        "MAX_LEN = 1000\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "RANDOM_SEED = 42\n",
        "RESULTS_DIR = 'results_fasta'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PogRCldLfvjQ"
      },
      "outputs": [],
      "source": [
        "def read_fasta(fasta_path):\n",
        "    \"\"\"Parse FASTA → return list of (header, sequence).\"\"\"\n",
        "    seqs = []\n",
        "    header = None\n",
        "    seq = []\n",
        "\n",
        "    with open(fasta_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            if line.startswith(\">\"):\n",
        "                if header and seq:\n",
        "                    seqs.append((header, \"\".join(seq)))\n",
        "                header = line[1:]   # remove '>'\n",
        "                seq = []\n",
        "            else:\n",
        "                seq.append(line)\n",
        "\n",
        "        if header and seq:\n",
        "            seqs.append((header, \"\".join(seq)))\n",
        "\n",
        "    return seqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5z9eNIV5fxvl"
      },
      "outputs": [],
      "source": [
        "def infer_label(header, scenario):\n",
        "    \"\"\"Extract labels from FASTA header.\"\"\"\n",
        "    h = header.lower()\n",
        "\n",
        "    if scenario == 1:\n",
        "        if \"human\" in h:\n",
        "            return \"human\"\n",
        "        elif \"mouse\" in h:\n",
        "            return \"mouse\"\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot infer binary label from header: {header}\")\n",
        "\n",
        "    else:  # scenario 2\n",
        "        if \"human_enhancer\" in h:\n",
        "            return \"human_enhancer\"\n",
        "        elif \"mouse_enhancer\" in h:\n",
        "            return \"mouse_enhancer\"\n",
        "            return \"no_enhancer\"\n",
        "        elif \"no_enhancer\" in h:\n",
        "            return \"no_enhancer\"\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot infer multi-class label from header: {header}\")\n",
        "\n",
        "def load_fasta_as_df(fasta_path, scenario):\n",
        "    data = read_fasta(fasta_path)\n",
        "    rows = []\n",
        "\n",
        "    for header, seq in data:\n",
        "        label = infer_label(header, scenario)\n",
        "        rows.append([header, seq, label])\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=[\"id\", \"sequence\", \"label\"])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NdTU6AFRf6TP"
      },
      "outputs": [],
      "source": [
        "def clean_seq(s):\n",
        "    s = str(s).upper()\n",
        "    s = ''.join([c if c in 'ACGT' else random.choice('ACGT') for c in s])\n",
        "    return s\n",
        "\n",
        "def pad_trunc(seq, maxlen=MAX_LEN):\n",
        "    if len(seq) >= maxlen:\n",
        "        return seq[:maxlen]\n",
        "    return seq + (\"A\" * (maxlen - len(seq)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0j9xAOevgQYs"
      },
      "outputs": [],
      "source": [
        "INT_MAP = {'A':1, 'C':3, 'G':2, 'T':4}\n",
        "ATOM_MAP = {'A':70, 'C':58, 'G':78, 'T':66}\n",
        "EIIP_MAP = {'A':0.1260, 'C':0.1340, 'G':0.0806, 'T':0.1335}\n",
        "\n",
        "def encode_integer(seq):\n",
        "    return np.array([INT_MAP[c] for c in seq], dtype=float)\n",
        "\n",
        "def encode_atomic(seq):\n",
        "    return np.array([ATOM_MAP[c] for c in seq], dtype=float)\n",
        "\n",
        "def encode_eiip(seq):\n",
        "    return np.array([EIIP_MAP[c] for c in seq], dtype=float)\n",
        "\n",
        "def encode_bfdna(seq):\n",
        "    L = len(seq)\n",
        "    counts = {b: seq.count(b) for b in \"ACGT\"}\n",
        "    freq = {b: counts[b] / L for b in \"ACGT\"}\n",
        "    return np.array([freq[c] for c in seq], dtype=float)\n",
        "\n",
        "ENCODERS = {\n",
        "    'integer': encode_integer,\n",
        "    'atomic': encode_atomic,\n",
        "    'eiip': encode_eiip,\n",
        "    'bfdna': encode_bfdna\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HySBl25fgTJg"
      },
      "outputs": [],
      "source": [
        "def build_Xy(df, encoding='bfdna', scenario=1):\n",
        "    enc = ENCODERS[encoding]\n",
        "\n",
        "    df['sequence'] = df['sequence'].apply(clean_seq)\n",
        "    df['sequence'] = df['sequence'].apply(lambda s: pad_trunc(s, MAX_LEN))\n",
        "\n",
        "    X = np.stack([enc(s) for s in df['sequence']])\n",
        "\n",
        "    if scenario == 1:\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(df['label'])\n",
        "        return X[..., np.newaxis], y, le.classes_\n",
        "    else:\n",
        "        lb = LabelBinarizer()\n",
        "        y_bin = lb.fit_transform(df['label'])\n",
        "        if y_bin.ndim == 1:\n",
        "            y_bin = np.vstack([1-y_bin, y_bin]).T\n",
        "        return X[..., np.newaxis], y_bin, lb.classes_\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1MuGKSgtgVcV"
      },
      "outputs": [],
      "source": [
        "def minmax_scale_train_test(X_train, X_val, X_test):\n",
        "    L = X_train.shape[1]\n",
        "    train_flat = X_train.reshape(len(X_train), L)\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_flat)\n",
        "\n",
        "    val_scaled = scaler.transform(X_val.reshape(len(X_val), L))\n",
        "    test_scaled = scaler.transform(X_test.reshape(len(X_test), L))\n",
        "\n",
        "    return train_scaled[..., None], val_scaled[..., None], test_scaled[..., None], scaler\n",
        "\n",
        "# Model architectures identical to paper\n",
        "def build_model_scenario1(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(inputs)\n",
        "    x = layers.Activation(\"selu\")(x)\n",
        "    x = layers.Dropout(0.15)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Activation(\"selu\")(x)\n",
        "    x = layers.Dropout(0.20)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "    x = layers.Activation(\"selu\")(x)\n",
        "    x = layers.Dropout(0.20)(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation=\"selu\")(x)\n",
        "    x = layers.Dense(256, activation=\"selu\")(x)\n",
        "    x = layers.Dense(128, activation=\"selu\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer=optimizers.RMSprop(),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def build_model_scenario2(input_shape, classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "    x = layers.Activation(\"selu\")(x)\n",
        "    x = layers.Dropout(0.15)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "    x = layers.Activation(\"selu\")(x)\n",
        "    x = layers.Dropout(0.20)(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation=\"selu\")(x)\n",
        "    x = layers.Dense(128, activation=\"selu\")(x)\n",
        "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer=optimizers.Adam(),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BoORMtkugcAw"
      },
      "outputs": [],
      "source": [
        "def train_and_eval(X, y, scenario, encoding):\n",
        "    # split 75/15/15\n",
        "    if scenario == 1:\n",
        "        strat = y\n",
        "    else:\n",
        "        strat = np.argmax(y, axis=1)\n",
        "\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(X, y,\n",
        "                                                      test_size=0.30,\n",
        "                                                      random_state=RANDOM_SEED,\n",
        "                                                      stratify=strat)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp,\n",
        "                                                    test_size=0.50,\n",
        "                                                    random_state=RANDOM_SEED,\n",
        "                                                    stratify=(y_tmp if scenario==1 else np.argmax(y_tmp,axis=1)))\n",
        "\n",
        "    X_train_s, X_val_s, X_test_s, _ = minmax_scale_train_test(X_train, X_val, X_test)\n",
        "\n",
        "    input_shape = X_train_s.shape[1:]\n",
        "\n",
        "    if scenario == 1:\n",
        "        model = build_model_scenario1(input_shape)\n",
        "    else:\n",
        "        model = build_model_scenario2(input_shape, y.shape[1])\n",
        "\n",
        "    es = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "    ckpt = callbacks.ModelCheckpoint(\n",
        "        os.path.join(RESULTS_DIR, f\"{encoding}_sc{scenario}.h5\"),\n",
        "        save_best_only=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_s, y_train,\n",
        "        validation_data=(X_val_s, y_val),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=[es, ckpt],\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # evaluation\n",
        "    preds = model.predict(X_test_s)\n",
        "    if scenario == 1:\n",
        "        y_pred = (preds.ravel() >= 0.5).astype(int)\n",
        "        print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "    else:\n",
        "        y_pred = np.argmax(preds, axis=1)\n",
        "        y_true = np.argmax(y_test, axis=1)\n",
        "        print(\"Accuracy:\", metrics.accuracy_score(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "IydxYJO2gfsK",
        "outputId": "0a83365d-d782-499c-ebb2-4413dca7c082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75/75 - 188s - 3s/step - accuracy: 0.5384 - loss: 1.7535 - val_accuracy: 0.5871 - val_loss: 0.7141\n",
            "Epoch 2/30\n",
            "75/75 - 198s - 3s/step - accuracy: 0.5291 - loss: 0.8995 - val_accuracy: 0.5871 - val_loss: 0.7235\n",
            "Epoch 3/30\n",
            "75/75 - 216s - 3s/step - accuracy: 0.5229 - loss: 0.8278 - val_accuracy: 0.4129 - val_loss: 12.1409\n",
            "Epoch 4/30\n",
            "75/75 - 206s - 3s/step - accuracy: 0.5249 - loss: 0.7680 - val_accuracy: 0.4129 - val_loss: 13.8902\n",
            "Epoch 5/30\n",
            "75/75 - 218s - 3s/step - accuracy: 0.5451 - loss: 0.7323 - val_accuracy: 0.4129 - val_loss: 33.7593\n",
            "Epoch 6/30\n",
            "75/75 - 222s - 3s/step - accuracy: 0.5484 - loss: 0.7229 - val_accuracy: 0.4129 - val_loss: 13.2253\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 844ms/step\n",
            "Accuracy: 0.587890625\n"
          ]
        }
      ],
      "source": [
        "SCENARIO = 1             # change to 2 for multi-class\n",
        "ENCODING = \"bfdna\"       # options: bfdna, eiip, integer, atomic\n",
        "\n",
        "df = load_fasta_as_df(FASTA_PATH, scenario=SCENARIO)\n",
        "X, y, classes = build_Xy(df, encoding=ENCODING, scenario=SCENARIO)\n",
        "train_and_eval(X, y, scenario=SCENARIO, encoding=ENCODING)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "98Tlq2T6giRv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
